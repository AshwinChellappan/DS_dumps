{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import ExtraTreesClassifier,RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from pylab import rcParams\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score, recall_score, confusion_matrix\n",
    "from sklearn.metrics import f1_score, roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=pd.read_csv('Train_Set_90621.csv')\n",
    "df_test=pd.read_csv('Test_Set_90621.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(83623, 28)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(195118, 29)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Application ID                      0\n",
       "Bank Masked                        80\n",
       "Bank Type                          80\n",
       "Approved_Timestamp                426\n",
       "Name Masked                         1\n",
       "Business Owner State                3\n",
       "Business_Industry_Type_Code         0\n",
       "Approved_Year                       0\n",
       "New Business                       36\n",
       "Term                                0\n",
       "BankState                          81\n",
       "Interest Rate                       0\n",
       "Employees                           0\n",
       "Gross Disbursed Amount              0\n",
       "Term_years                          0\n",
       "Jobs Retained                       0\n",
       "Male to Female Employees Ratio      0\n",
       "Expected Company Income             3\n",
       "Funds available with company        0\n",
       "Gross_Apprv_Amount                  0\n",
       "Company Branch Code                 0\n",
       "City or Rural                       0\n",
       "Jobs Generated                      0\n",
       "Carry-forward Credit              978\n",
       "Documents Provided                552\n",
       "Balance Left                        0\n",
       "Amount Defaulted                    0\n",
       "Final_Appved_Amount                 0\n",
       "Default_Status                      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Application ID                      0\n",
       "Bank Masked                        48\n",
       "Bank Type                          48\n",
       "Approved_Timestamp                174\n",
       "Name Masked                         0\n",
       "Business Owner State                0\n",
       "Business_Industry_Type_Code         0\n",
       "Approved_Year                       0\n",
       "New Business                       15\n",
       "Term                                0\n",
       "BankState                          48\n",
       "Interest Rate                       0\n",
       "Employees                           0\n",
       "Gross Disbursed Amount              0\n",
       "Term_years                          0\n",
       "Jobs Retained                       0\n",
       "Male to Female Employees Ratio      0\n",
       "Expected Company Income             0\n",
       "Funds available with company        0\n",
       "Gross_Apprv_Amount                  0\n",
       "Company Branch Code                 0\n",
       "City or Rural                       0\n",
       "Jobs Generated                      0\n",
       "Carry-forward Credit              412\n",
       "Documents Provided                247\n",
       "Balance Left                        0\n",
       "Amount Defaulted                    0\n",
       "Final_Appved_Amount                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['Documents Provided']=df_train['Documents Provided'].fillna('N')\n",
    "df_train['Carry-forward Credit']=df_train['Carry-forward Credit'].fillna('N')\n",
    "df_train['BankState']=df_train['BankState'].fillna('UNKNOWN')\n",
    "df_train['Bank Type']=df_train['Bank Type'].fillna('GOVT')\n",
    "df_train['Business Owner State']=df_train['Business Owner State'].fillna('UNKNOWN')\n",
    "df_train['New Business']=df_train['New Business'].fillna('0.0')\n",
    "df_train['Expected Company Income']=df_train['Expected Company Income'].fillna(df_train['Expected Company Income'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['Documents Provided']=df_test['Documents Provided'].fillna('N')\n",
    "df_test['Carry-forward Credit']=df_test['Carry-forward Credit'].fillna('N')\n",
    "df_test['BankState']=df_test['BankState'].fillna('UNKNOWN')\n",
    "df_test['Bank Type']=df_test['Bank Type'].fillna('GOVT')\n",
    "df_test['Business Owner State']=df_test['Business Owner State'].fillna('UNKNOWN')\n",
    "df_test['New Business']=df_test['New Business'].fillna('0.0')\n",
    "df_test['Expected Company Income']=df_test['Expected Company Income'].fillna(df_test['Expected Company Income'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping Null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.dropna(inplace=True)\n",
    "df_test.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['Expected Company Income']=df_train['Expected Company Income'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Application ID                       97588.50\n",
      "Business_Industry_Type_Code         326620.00\n",
      "Approved_Year                            6.00\n",
      "New Business                             1.00\n",
      "Term                                    60.00\n",
      "Interest Rate                            5.00\n",
      "Employees                               14.00\n",
      "Gross Disbursed Amount            13830162.50\n",
      "Term_years                               5.00\n",
      "Jobs Retained                            4.00\n",
      "Male to Female Employees Ratio          12.00\n",
      "Expected Company Income            6700000.00\n",
      "Funds available with company       1078811.75\n",
      "Gross_Apprv_Amount                13440000.00\n",
      "Company Branch Code                      0.00\n",
      "City or Rural                            1.00\n",
      "Jobs Generated                           1.00\n",
      "Balance Left                             0.00\n",
      "Amount Defaulted                         0.00\n",
      "Final_Appved_Amount               10762500.00\n",
      "Default_Status                           0.00\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "Q1=df_train.quantile(0.25)\n",
    "Q3=df_train.quantile(0.75)\n",
    "IQR=Q3-Q1\n",
    "print(IQR)\n",
    "#df = df[~((df < (Q1 - 1.5 * IQR)) |(df > (Q3 + 1.5 * IQR))).any(axis=1)]\n",
    "#df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Droping ID columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=df_train.drop(columns=['Application ID','Bank Masked','Name Masked','Approved_Timestamp'],axis=1)\n",
    "df_test=df_test.drop(columns=['Application ID','Bank Masked','Name Masked','Approved_Timestamp'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cat_train=df_train.select_dtypes('object')\n",
    "df_cat_test=df_test.select_dtypes('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cat_train=df_cat_train.drop(columns=['Business Owner State','BankState'],axis=0)\n",
    "df_cat_test=df_cat_test.drop(columns=['Business Owner State','BankState'],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cat_train_x1 = pd.get_dummies(df_cat_train, drop_first=True)\n",
    "df_cat_test_x1 = pd.get_dummies(df_cat_test, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['Business Owner State']=le.fit_transform(df_train['Business Owner State'])\n",
    "df_train['BankState']=le.fit_transform(df_train['BankState'])\n",
    "\n",
    "df_test['Business Owner State']=le.fit_transform(df_test['Business Owner State'])\n",
    "df_test['BankState']=le.fit_transform(df_test['BankState'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import SelectKBest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "XTrain=df_train.select_dtypes('int64')\n",
    "XTest=df_test.select_dtypes('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain=pd.concat([XTrain,df_cat_train_x1],axis=1)\n",
    "xtest=pd.concat([XTest,df_cat_test_x1],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "xi=xtrain.drop('Default_Status',axis=1)\n",
    "xc=xtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df_train['Default_Status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(193042, 21)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xi.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "standardscalar=StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_scaled=standardscalar.fit_transform(xi)\n",
    "x_test_scaled=standardscalar.fit_transform(xc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg=LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(x_train_scaled, y,test_size=0.33,random_state=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg.fit(X_train,Y_train)\n",
    "#Predicting variable for the test dataset\n",
    "y_pred_train = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import f1_score, roc_auc_score, roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[51393   760]\n",
      " [ 9449  2102]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(Y_test, y_pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.99      0.91     52153\n",
      "           1       0.73      0.18      0.29     11551\n",
      "\n",
      "    accuracy                           0.84     63704\n",
      "   macro avg       0.79      0.58      0.60     63704\n",
      "weighted avg       0.82      0.84      0.80     63704\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(Y_test, y_pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8839790280045209\n"
     ]
    }
   ],
   "source": [
    "decision_tree = DecisionTreeClassifier(random_state=10,criterion='gini')#Default Gini\n",
    "decision_tree = decision_tree.fit(X_train, Y_train)\n",
    "y_pred = decision_tree.predict(X_test)\n",
    "print(\"Accuracy:\",accuracy_score(Y_test, y_pred))\n",
    "#Gini-Accuracy: 0.884292980032651\n",
    "#Entropy-Accuracy: 0.8839790280045209"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[48259  3894]\n",
      " [ 3497  8054]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.99      0.91     52153\n",
      "           1       0.74      0.18      0.29     11551\n",
      "\n",
      "    accuracy                           0.84     63704\n",
      "   macro avg       0.79      0.58      0.60     63704\n",
      "weighted avg       0.82      0.84      0.80     63704\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(Y_test, y_pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE \n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = SMOTE(random_state=123)\n",
    "X_sm , y_sm = sm.fit_resample(x_train_scaled,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train , x_test , y_train ,y_test = train_test_split(X_sm,y_sm,test_size= 0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AS20188795\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "logreg.fit(x_train,y_train)\n",
    "#Predicting variable for the test dataset\n",
    "y_pred_train = logreg.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7980363044207098\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\",accuracy_score(y_test, y_pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.84      0.81     52105\n",
      "           1       0.83      0.76      0.79     52290\n",
      "\n",
      "    accuracy                           0.80    104395\n",
      "   macro avg       0.80      0.80      0.80    104395\n",
      "weighted avg       0.80      0.80      0.80    104395\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, y_pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9214521768283922\n",
      "[[47844  4261]\n",
      " [ 3939 48351]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.92      0.92     52105\n",
      "           1       0.92      0.92      0.92     52290\n",
      "\n",
      "    accuracy                           0.92    104395\n",
      "   macro avg       0.92      0.92      0.92    104395\n",
      "weighted avg       0.92      0.92      0.92    104395\n",
      "\n"
     ]
    }
   ],
   "source": [
    "decision_tree = decision_tree.fit(x_train, y_train)\n",
    "y_pred = decision_tree.predict(x_test)\n",
    "print(\"Accuracy:\",accuracy_score(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy after 10 fold cross validation:  0.92\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(estimator = decision_tree, \n",
    "                         X = x_train, \n",
    "                         y = y_train, \n",
    "                         cv = 10, \n",
    "                         scoring = 'accuracy')\n",
    "print(\"Mean accuracy after 10 fold cross validation: \", round(scores.mean(), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9429666171751521\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.97      0.94     52105\n",
      "           1       0.97      0.91      0.94     52290\n",
      "\n",
      "    accuracy                           0.94    104395\n",
      "   macro avg       0.94      0.94      0.94    104395\n",
      "weighted avg       0.94      0.94      0.94    104395\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_classification = RandomForestClassifier(n_estimators = 10, random_state = 10)\n",
    "rf_model = rf_classification.fit(x_train, y_train)\n",
    "y_pred = rf_model.predict(x_test)\n",
    "print(\"Accuracy:\",accuracy_score(y_test, y_pred))\n",
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "continuous-multioutput format is not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-97-ecb2868f6575>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mstack_model_AdaBoost\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0my_pred_prob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstack_model_AdaBoost\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'AUC score for the model with AdaBoost as final estimator:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred_prob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\u001b[0m in \u001b[0;36mroc_auc_score\u001b[1;34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001b[0m\n\u001b[0;32m    545\u001b[0m                                      sample_weight=sample_weight)\n\u001b[0;32m    546\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# multilabel-indicator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 547\u001b[1;33m         return _average_binary_score(partial(_binary_roc_auc_score,\n\u001b[0m\u001b[0;32m    548\u001b[0m                                              max_fpr=max_fpr),\n\u001b[0;32m    549\u001b[0m                                      \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_base.py\u001b[0m in \u001b[0;36m_average_binary_score\u001b[1;34m(binary_metric, y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[0;32m     72\u001b[0m     \u001b[0my_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"binary\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"multilabel-indicator\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"{0} format is not supported\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"binary\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: continuous-multioutput format is not supported"
     ]
    }
   ],
   "source": [
    "base_learners = [('Decision Tree', DecisionTreeClassifier()),\n",
    "                 ('Random Forest', RandomForestClassifier())]\n",
    "stack_model_AdaBoost = StackingClassifier(estimators = base_learners, final_estimator = AdaBoostClassifier(random_state = 8))\n",
    "stack_model_AdaBoost.fit(x_train, y_train)\n",
    "y_pred_prob = stack_model_AdaBoost.predict_proba(x_test)[:, 1]\n",
    "print('AUC score for the model with AdaBoost as final estimator:', roc_auc_score(x_test, y_pred_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tuned_paramaters = [{'criterion': ['entropy', 'gini'],\n",
    "#                     'max_depth': range(2, 10),\n",
    "#                     'min_samples_split': range(2,10)}]\n",
    "#decision_tree_model = DecisionTreeClassifier(random_state = 10)\n",
    "#tree_grid = GridSearchCV(estimator = decision_tree_model, \n",
    "#                         param_grid = tuned_paramaters, \n",
    "#                         cv = 5)\n",
    "#tree_grid.fit(x_train, y_train)\n",
    "#print('Best parameters for Decision Tree Classifier: ', tree_grid.best_params_, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xg\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AS20188795\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[08:33:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"class_weight\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[08:33:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "clf2 = xg.XGBClassifier(class_weight='balanced').fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AS20188795\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass classes=[0 1], y=185850    0\n",
      "78924     0\n",
      "87194     0\n",
      "179887    0\n",
      "87099     0\n",
      "         ..\n",
      "194681    0\n",
      "168008    0\n",
      "174179    1\n",
      "6543      0\n",
      "133325    0\n",
      "Name: Default_Status, Length: 130729, dtype: int64 as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.61054652, 2.76149134])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import class_weight\n",
    "#class_weight='balanced' uses the values of y to automatically adjust weights inversely proportional to class frequencies in the input data\n",
    "class_weight.compute_class_weight('balanced', np.unique(Y_train), Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Y_Test_Pred = clf2.predict(x_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  0.9298003265101092\n",
      "Precision =  0.9431576311506198\n",
      "Recall =  0.6521513288892736\n",
      "F1 Score =  0.7711127034496877\n"
     ]
    }
   ],
   "source": [
    "generate_model_report(Y_test, Y_Test_Pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_model_report(y_actual, y_predicted):\n",
    "    print(\"Accuracy = \" , accuracy_score(y_actual, y_predicted))\n",
    "    print(\"Precision = \" ,precision_score(y_actual, y_predicted))\n",
    "    print(\"Recall = \" ,recall_score(y_actual, y_predicted))\n",
    "    print(\"F1 Score = \" ,f1_score(y_actual, y_predicted))\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Specs</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Amount Defaulted</td>\n",
       "      <td>3.811323e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Final_Appved_Amount</td>\n",
       "      <td>3.693419e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Gross_Apprv_Amount</td>\n",
       "      <td>3.664286e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Gross Disbursed Amount</td>\n",
       "      <td>3.091477e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Expected Company Income</td>\n",
       "      <td>1.514742e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Company Branch Code</td>\n",
       "      <td>2.993971e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Funds available with company</td>\n",
       "      <td>5.791731e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Term</td>\n",
       "      <td>4.806896e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Balance Left</td>\n",
       "      <td>2.990999e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Business_Industry_Type_Code</td>\n",
       "      <td>1.299905e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Jobs Generated</td>\n",
       "      <td>1.141116e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Employees</td>\n",
       "      <td>9.576972e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Jobs Retained</td>\n",
       "      <td>9.158334e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Term_years</td>\n",
       "      <td>3.969661e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>City or Rural</td>\n",
       "      <td>1.197810e+03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Specs         Score\n",
       "16              Amount Defaulted  3.811323e+11\n",
       "17           Final_Appved_Amount  3.693419e+10\n",
       "11            Gross_Apprv_Amount  3.664286e+10\n",
       "5         Gross Disbursed Amount  3.091477e+10\n",
       "9        Expected Company Income  1.514742e+09\n",
       "12           Company Branch Code  2.993971e+06\n",
       "10  Funds available with company  5.791731e+05\n",
       "2                           Term  4.806896e+05\n",
       "15                  Balance Left  2.990999e+05\n",
       "0    Business_Industry_Type_Code  1.299905e+05\n",
       "14                Jobs Generated  1.141116e+05\n",
       "4                      Employees  9.576972e+04\n",
       "7                  Jobs Retained  9.158334e+04\n",
       "6                     Term_years  3.969661e+04\n",
       "13                 City or Rural  1.197810e+03"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_feature=SelectKBest(score_func=chi2,k=10)\n",
    "fit=best_feature.fit(xi,y)\n",
    "df_score=pd.DataFrame(fit.scores_)\n",
    "df_column=pd.DataFrame(xi.columns)\n",
    "featurescore=pd.concat([df_column,df_score],axis=1)\n",
    "featurescore.columns=['Specs','Score']\n",
    "featurescore.nlargest(15,'Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "xi_best=xi[['City or Rural','Term_years','Jobs Retained','Business_Industry_Type_Code','Balance Left','Term','Funds available with company','Company Branch Code','Expected Company Income','Gross Disbursed Amount','Gross_Apprv_Amount','Final_Appved_Amount','Amount Defaulted']]\n",
    "xc_best=xc[['City or Rural','Term_years','Jobs Retained','Business_Industry_Type_Code','Balance Left','Term','Funds available with company','Company Branch Code','Expected Company Income','Gross Disbursed Amount','Gross_Apprv_Amount','Final_Appved_Amount','Amount Defaulted']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x=df_train[['Amount Defaulted','Final_Appved_Amount','Gross_Apprv_Amount','Gross Disbursed Amount','Company Branch Code','Funds available with company','Term','Balance Left','Jobs Generated','Employees','Jobs Retained','Business_Industry_Type_Code','Term_years','City or Rural','Male to Female Employees Ratio']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City or Rural</th>\n",
       "      <th>Term_years</th>\n",
       "      <th>Jobs Retained</th>\n",
       "      <th>Business_Industry_Type_Code</th>\n",
       "      <th>Balance Left</th>\n",
       "      <th>Term</th>\n",
       "      <th>Funds available with company</th>\n",
       "      <th>Company Branch Code</th>\n",
       "      <th>Expected Company Income</th>\n",
       "      <th>Gross Disbursed Amount</th>\n",
       "      <th>Gross_Apprv_Amount</th>\n",
       "      <th>Final_Appved_Amount</th>\n",
       "      <th>Amount Defaulted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>525161</td>\n",
       "      <td>0</td>\n",
       "      <td>219</td>\n",
       "      <td>780590</td>\n",
       "      <td>25650</td>\n",
       "      <td>3500000</td>\n",
       "      <td>18550000</td>\n",
       "      <td>18550000</td>\n",
       "      <td>13912500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>1231</td>\n",
       "      <td>0</td>\n",
       "      <td>71</td>\n",
       "      <td>1835637</td>\n",
       "      <td>0</td>\n",
       "      <td>1666667</td>\n",
       "      <td>3045000</td>\n",
       "      <td>2450000</td>\n",
       "      <td>1225000</td>\n",
       "      <td>2369500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>322442</td>\n",
       "      <td>0</td>\n",
       "      <td>84</td>\n",
       "      <td>2373333</td>\n",
       "      <td>0</td>\n",
       "      <td>1333333</td>\n",
       "      <td>1750000</td>\n",
       "      <td>1750000</td>\n",
       "      <td>1487500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>1231</td>\n",
       "      <td>0</td>\n",
       "      <td>300</td>\n",
       "      <td>2346786</td>\n",
       "      <td>1</td>\n",
       "      <td>333333</td>\n",
       "      <td>38850000</td>\n",
       "      <td>38850000</td>\n",
       "      <td>29137500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>1231</td>\n",
       "      <td>0</td>\n",
       "      <td>153</td>\n",
       "      <td>2382995</td>\n",
       "      <td>1</td>\n",
       "      <td>333333</td>\n",
       "      <td>2800000</td>\n",
       "      <td>2800000</td>\n",
       "      <td>2380000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   City or Rural  Term_years  Jobs Retained  Business_Industry_Type_Code  \\\n",
       "0              1          18             18                       525161   \n",
       "1              1           6             10                         1231   \n",
       "2              2           7             10                       322442   \n",
       "3              1          25              2                         1231   \n",
       "4              2          13              0                         1231   \n",
       "\n",
       "   Balance Left  Term  Funds available with company  Company Branch Code  \\\n",
       "0             0   219                        780590                25650   \n",
       "1             0    71                       1835637                    0   \n",
       "2             0    84                       2373333                    0   \n",
       "3             0   300                       2346786                    1   \n",
       "4             0   153                       2382995                    1   \n",
       "\n",
       "   Expected Company Income  Gross Disbursed Amount  Gross_Apprv_Amount  \\\n",
       "0                  3500000                18550000            18550000   \n",
       "1                  1666667                 3045000             2450000   \n",
       "2                  1333333                 1750000             1750000   \n",
       "3                   333333                38850000            38850000   \n",
       "4                   333333                 2800000             2800000   \n",
       "\n",
       "   Final_Appved_Amount  Amount Defaulted  \n",
       "0             13912500                 0  \n",
       "1              1225000           2369500  \n",
       "2              1487500                 0  \n",
       "3             29137500                 0  \n",
       "4              2380000                 0  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "xi_train_scaled=standardscalar.fit_transform(xi)\n",
    "xc_test_scaled=standardscalar.fit_transform(xc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AS20188795\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(xi_train_scaled, y,test_size=0.33,random_state=60)\n",
    "logreg.fit(X_train,Y_train)\n",
    "y_pred_train = logreg.predict(xc_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.99      0.91     52821\n",
      "           1       0.74      0.18      0.29     11568\n",
      "\n",
      "    accuracy                           0.84     64389\n",
      "   macro avg       0.79      0.58      0.60     64389\n",
      "weighted avg       0.83      0.84      0.80     64389\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(Y_test, y_pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_learners = [('Decision Tree', DecisionTreeClassifier()),\n",
    "                 ('Random Forest', RandomForestClassifier())]\n",
    "stack_model_AdaBoost = StackingClassifier(estimators = base_learners, final_estimator = AdaBoostClassifier(random_state = 8))\n",
    "stack_model_AdaBoost.fit(X_train, Y_train)\n",
    "y_pred_prob = stack_model_AdaBoost.predict_proba(xc_test_scaled)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC score for the model with AdaBoost as final estimator: 0.9411324074290102\n"
     ]
    }
   ],
   "source": [
    "print('AUC score for the model with AdaBoost as final estimator:', roc_auc_score(Y_test, y_pred_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('Sample_Sub.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['Default_Status']=y_pred_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('Sample_Sub.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
