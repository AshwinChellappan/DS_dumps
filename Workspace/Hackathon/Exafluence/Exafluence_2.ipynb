{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import ExtraTreesClassifier,RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from pylab import rcParams\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score, recall_score, confusion_matrix\n",
    "from sklearn.metrics import f1_score, roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import precision_score, recall_score, confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import f1_score, roc_auc_score, roc_curve\n",
    "from imblearn.over_sampling import SMOTE \n",
    "standardscalar=StandardScaler()\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=pd.read_csv('Train_Set_90621.csv')\n",
    "df_test=pd.read_csv('Test_Set_90621.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['Documents Provided']=df_train['Documents Provided'].fillna('N')\n",
    "df_train['Carry-forward Credit']=df_train['Carry-forward Credit'].fillna('N')\n",
    "df_train['BankState']=df_train['BankState'].fillna('UNKNOWN')\n",
    "df_train['Bank Type']=df_train['Bank Type'].fillna('GOVT')\n",
    "df_train['Business Owner State']=df_train['Business Owner State'].fillna('UNKNOWN')\n",
    "df_train['New Business']=df_train['New Business'].fillna('0.0')\n",
    "df_train['Expected Company Income']=df_train['Expected Company Income'].fillna(df_train['Expected Company Income'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['Documents Provided']=df_test['Documents Provided'].fillna('N')\n",
    "df_test['Carry-forward Credit']=df_test['Carry-forward Credit'].fillna('N')\n",
    "df_test['BankState']=df_test['BankState'].fillna('UNKNOWN')\n",
    "df_test['Bank Type']=df_test['Bank Type'].fillna('GOVT')\n",
    "df_test['Business Owner State']=df_test['Business Owner State'].fillna('UNKNOWN')\n",
    "df_test['New Business']=df_test['New Business'].fillna('0.0')\n",
    "df_test['Expected Company Income']=df_test['Expected Company Income'].fillna(df_test['Expected Company Income'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['Expected Company Income']=df_train['Expected Company Income'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=df_train.drop(columns=['Application ID','Bank Masked','Name Masked','Approved_Timestamp'],axis=1)\n",
    "df_test=df_test.drop(columns=['Application ID','Bank Masked','Name Masked','Approved_Timestamp'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cat_train=df_train.select_dtypes('object')\n",
    "df_cat_test=df_test.select_dtypes('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cat_train=df_cat_train.drop(columns=['Business Owner State','BankState'],axis=0)\n",
    "df_cat_test=df_cat_test.drop(columns=['Business Owner State','BankState'],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cat_train_x1 = pd.get_dummies(df_cat_train, drop_first=True)\n",
    "df_cat_test_x1 = pd.get_dummies(df_cat_test, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['Business Owner State']=le.fit_transform(df_train['Business Owner State'])\n",
    "df_train['BankState']=le.fit_transform(df_train['BankState'])\n",
    "\n",
    "df_test['Business Owner State']=le.fit_transform(df_test['Business Owner State'])\n",
    "df_test['BankState']=le.fit_transform(df_test['BankState'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "XTrain=df_train.select_dtypes('int64')\n",
    "XTest=df_test.select_dtypes('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain=pd.concat([XTrain,df_cat_train_x1],axis=1)\n",
    "xtest=pd.concat([XTest,df_cat_test_x1],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "xi=xtrain.drop('Default_Status',axis=1)\n",
    "xc=xtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df_train['Default_Status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_scaled=standardscalar.fit_transform(xi)\n",
    "x_test_scaled=standardscalar.fit_transform(xc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg=LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = SMOTE(random_state=123)\n",
    "X_sm , y_sm = sm.fit_resample(x_train_scaled,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train , x_test , y_train ,y_test = train_test_split(X_sm,y_sm,test_size= 0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AS20188795\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "logreg.fit(x_train,y_train)\n",
    "#Predicting variable for the test dataset\n",
    "y_pred_train = logreg.predict(x_test)\n",
    "#y_pred_train = logreg.predict(x_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.85      0.81     52655\n",
      "           1       0.83      0.76      0.80     52866\n",
      "\n",
      "    accuracy                           0.81    105521\n",
      "   macro avg       0.81      0.81      0.81    105521\n",
      "weighted avg       0.81      0.81      0.81    105521\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, y_pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xg\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:08:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AS20188795\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "clf2 = xg.XGBClassifier().fit(x_train,y_train)\n",
    "y_pred_xgb=clf2.predict(x_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('Sample_Sub.csv')\n",
    "submission['Default_Status']=y_pred_xgb\n",
    "submission.to_csv('Sample_Sub.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
